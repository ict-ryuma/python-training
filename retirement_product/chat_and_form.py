import streamlit as st
import pandas as pd
import joblib
import os
from dotenv import load_dotenv
from openai import OpenAI

# ğŸ” ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿
load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# ğŸ¯ ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(page_title="é€€è·äºˆæ¸¬ & ç›¸è«‡ãƒãƒ£ãƒƒãƒˆ")
st.title("ğŸ’¼ é€€è·ãƒªã‚¹ã‚¯è¨ºæ–­")

# âœ… ãƒ¢ãƒ‡ãƒ«ã¨ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ã®èª­ã¿è¾¼ã¿
model = joblib.load("model.pkl")
le_job = joblib.load("le_job.pkl")
le_gender = joblib.load("le_gender.pkl")
le_divorce = joblib.load("le_divorce.pkl")

# ğŸ“ é€€è·äºˆæ¸¬ãƒ•ã‚©ãƒ¼ãƒ 
with st.form("input_form"):
    st.subheader("ğŸ§ª é€€è·äºˆæ¸¬ãƒ•ã‚©ãƒ¼ãƒ ")
    age = st.number_input("å¹´é½¢", 18, 70, 30)
    job = st.selectbox("è·æ¥­", ["å–¶æ¥­", "Pythonã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢", "Goã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢", "ãƒ‡ã‚¶ã‚¤ãƒŠãƒ¼"])
    overtime = st.slider("æ®‹æ¥­æ™‚é–“", 0, 100, 20)
    gender = st.selectbox("æ€§åˆ¥", ["ç”·æ€§", "å¥³æ€§"])
    divorce = st.selectbox("é›¢å©šçµŒé¨“", ["ãªã—", "ã‚ã‚Š"])
    power = st.slider("ãƒ‘ãƒ¯ãƒãƒ©ãƒ¬ãƒ™ãƒ«", 0, 10, 3)
    submitted = st.form_submit_button("é€€è·ç¢ºç‡ã‚’ãƒã‚§ãƒƒã‚¯ï¼")

# ğŸ¯ é€€è·äºˆæ¸¬ã®çµæœè¡¨ç¤ºï¼ˆï¼‹åŠ©è¨€ä»˜ãï¼‰
if submitted:
    df_base = {
        "å¹´é½¢": age,
        "è·æ¥­": le_job.transform([job])[0],
        "æ®‹æ¥­æ™‚é–“": overtime,
        "æ€§åˆ¥": le_gender.transform([gender])[0],
        "é›¢å©š": le_divorce.transform([divorce])[0],
    }

    df = pd.DataFrame([{**df_base, "ãƒ‘ãƒ¯ãƒãƒ©ãƒ¬ãƒ™ãƒ«": power}])
    proba = model.predict_proba(df)[0][1]
    pred = model.predict(df)[0]

    if pred:
        st.error(f"ğŸ˜± é€€è·ãƒªã‚¹ã‚¯é«˜ï¼ï¼ˆç¢ºç‡: {proba*100:.1f}ï¼…ï¼‰")

        if proba > 0.6:
            # ãƒ‘ãƒ¯ãƒãƒ©ãƒ¬ãƒ™ãƒ«èª¿æ•´ã§ãƒªã‚¹ã‚¯ä½æ¸›ã‚’æ¢ã‚‹
            best_level = power
            best_proba = proba
            for lvl in range(11):
                df_try = pd.DataFrame([{**df_base, "ãƒ‘ãƒ¯ãƒãƒ©ãƒ¬ãƒ™ãƒ«": lvl}])
                tmp_proba = model.predict_proba(df_try)[0][1]
                if tmp_proba < best_proba:
                    best_proba = tmp_proba
                    best_level = lvl

            if best_level != power:
                st.info(
                    f"ğŸ’¡ ãƒ‘ãƒ¯ãƒãƒ©ãƒ¬ãƒ™ãƒ«ã‚’ **{best_level}** ã«ã™ã‚‹ã¨é€€è·ãƒªã‚¹ã‚¯ãŒ **{best_proba*100:.1f}%** ã¾ã§ä¸‹ãŒã‚Šã¾ã™ã€‚\n"
                    f"è·å ´ã®ç’°å¢ƒæ”¹å–„ã‚„ç›¸è«‡ã®æ¤œè¨ã‚’ãŠã™ã™ã‚ã—ã¾ã™ã€‚"
                )
    else:
        st.success(f"ğŸ’ª ç¶šã‘ã‚‰ã‚Œã‚‹å¯èƒ½æ€§é«˜ï¼ï¼ˆç¢ºç‡: {proba*100:.1f}ï¼…ï¼‰")

# ğŸ’¬ GPTãƒãƒ£ãƒƒãƒˆç›¸è«‡ã‚¨ãƒªã‚¢
st.divider()
st.subheader("ğŸ’ ã‚«ã‚¦ãƒ³ã‚»ãƒ©ãƒ¼ã«æ‚©ã¿ç›¸è«‡")

if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

for msg in st.session_state.chat_history:
    with st.chat_message(msg["role"]):
        st.write(msg["content"])

user_msg = st.chat_input("æ‚©ã¿ã‚’è©±ã—ã¦ã¿ã¦ã­ï¼ˆä¾‹ï¼šä¸Šå¸ãŒæ€–ãã¦å‡ºç¤¾ã—ãŸããªã„â€¦ï¼‰")

if user_msg:
    st.session_state.chat_history.append({"role": "user", "content": user_msg})
    with st.chat_message("user"):
        st.write(user_msg)

    with st.chat_message("assistant"):
        with st.spinner("ã‚«ã‚¦ãƒ³ã‚»ãƒ©ãƒ¼ãŒè€ƒãˆä¸­..."):
            response = client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": "ã‚ãªãŸã¯å„ªã—ãä¸å¯§ã«äººã®å¿ƒã«å¯„ã‚Šæ·»ã†ã‚­ãƒ£ãƒªã‚¢ã‚«ã‚¦ãƒ³ã‚»ãƒ©ãƒ¼ã§ã™ã€‚"},
                    {"role": "user", "content": user_msg}
                ]
            )
            assistant_msg = response.choices[0].message.content
            st.write(assistant_msg)
            st.session_state.chat_history.append({"role": "assistant", "content": assistant_msg})
